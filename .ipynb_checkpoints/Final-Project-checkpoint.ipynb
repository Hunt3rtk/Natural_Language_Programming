{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b09e08-729d-4df0-814f-d49e7f084f61",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>NOTE</h3>\n",
    "    <p>Before you submit this assignment, <strong>make sure everything runs as expected</strong>:</p>\n",
    "    <ol>\n",
    "        <li><strong>restart the kernel</strong> (in the menubar, select <strong>Kernel → Restart</strong>)\n",
    "        <li><strong>run all cells</strong> (in the menubar, select <strong>Cell → Run All</strong>)</li>\n",
    "    </ol>\n",
    "    <p>Make sure to complete every cell that states \"<strong><TT>YOUR CODE IN THIS CELL</TT></strong>\".</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb7fe1-25eb-42df-ac84-6828ca20606a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Final Project\n",
    "**COMP-482: Winter 2023**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499febe-b6ed-4a36-b4dc-a643e9b81224",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* access a *real-world* dataset (e.g., used in **kaggle.com** competitions, etc.) rather than a *toy* dataset\n",
    "* download and apply *pre-trained machine learning models*\n",
    "* develop and evaluate model\n",
    "* evaluate different machine learning models on *complex* real-world tasks\n",
    "* work with a variety of industry-standard machine learning libraries (*Tensorflow*, *PyTorch*, *sklearn*, *NLTK*, etc.)\n",
    "* visually communicate data and experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37678043-d48b-4205-b71f-72f3fb41ab71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Instructions\n",
    "\n",
    "Write your **code** in the *code cells* located directly below each red *Write Code* block.\\\n",
    "Write your **text** in the *Markdown cells* that follow every **Task** description below. Also complete this Notebook's **Final Report** section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3983737",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    <p>The best approach to this assignment is to work on <strong>one task at a time</strong>. Treat each task as a step toward a destination.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f2825-6b22-4378-a31a-d02e923559bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "------\n",
    "## Preliminaries & Dependencies\n",
    "\n",
    "You will require the following **Python** packages to complete this assignment (it is likely many of these libraries are already installed via **Anaconda**, **Quiz #4**, etc.):\n",
    "* matplotlib\n",
    "* numpy\n",
    "* sklearn\n",
    "* tensorflow\n",
    "* tensorflow-hub\n",
    "* tensorflow-datasets\n",
    "* tfds-nightly\n",
    "* seaborn\n",
    "* nltk\n",
    "* pandas\n",
    "\n",
    "\n",
    "### Imports\n",
    "\n",
    "Import the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e084519-9419-4f64-8287-38c245f19138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "import seaborn\n",
    "import sklearn\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51feb5-8e31-4bf6-b468-608f17ea7717",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Cross Validation Of A Dataset\n",
    "\n",
    "The following example code demonstrates using the builtin cross validation module from the [**Scikit-Learn** library](https://scikit-learn.org/stable/modules/cross_validation.html).\\\n",
    "You will likely use a variation of the following code for all of the models you will be evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af18121c-0c1a-4cf0-a0c9-d627981376aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE\n",
    "\n",
    "# Code from:  https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "#import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn import datasets\n",
    "#from sklearn import svm\n",
    "\n",
    "# X = inputs or features of the data\n",
    "# y = output values from the data that we are trying to predict\n",
    "#X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "#X.shape, y.shape # shape displays the dimensions of the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff3faad-8a83-4d2b-b921-8f44bef5c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE\n",
    "\n",
    "# Train the model using 80% of the dataset then test (evaluate) the model on the other 20% of the dataset\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# shape displays the dimensions of the matrices\n",
    "#print(X_train.shape, y_train.shape)\n",
    "#print(X_test.shape, y_test.shape)\n",
    "\n",
    "#clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "#score = clf.score(X_test, y_test)\n",
    "#print(\"The performance of one run of the SVM model:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21809e3-a739-48dd-81ab-f21682a21cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "\n",
    "#scores = cross_val_score(clf, X, y, cv=5)\n",
    "#print(\"Scores for the 5 runs of the SVM model:\", scores)\n",
    "#print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb0e06-5f2b-49d4-bb94-9f8e6ffde2fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "## Task: Evaluating Language Knowledge   (5 Marks)\n",
    "\n",
    "See https://www.kaggle.com/competitions/feedback-prize-english-language-learning/overview.\n",
    "\n",
    "From [**Kaggle**](https://www.kaggle.com/competitions/feedback-prize-english-language-learning/overview):\n",
    "> The goal of this competition is to assess the language proficiency of 8th-12th grade English Language Learners (ELLs). Utilizing a dataset of essays written by ELLs will help to develop proficiency models that better supports all students.\n",
    "\n",
    "\n",
    "\n",
    "### Data Description\n",
    "The dataset presented here (the ELLIPSE corpus) comprises argumentative essays written by 8th-12th grade English Language Learners (ELLs). The essays have been scored according to six analytic measures: cohesion, syntax, vocabulary, phraseology, grammar, and conventions.\n",
    "\n",
    "> #### Files\n",
    "> \n",
    "> **train.csv** - The training set, comprising the full_text of each essay, identified by a unique text_id. The essays are also given a score for each of the seven analytic measures above: cohesion, etc. These analytic measures comprise the target for the competition.\\\n",
    "\\\n",
    "**test.csv** - For the test data we give only the full_text of an essay together with its text_id.\\\n",
    "\\\n",
    "**sample_submission.csv** - A submission file in the correct format. See the Evaluation page for details.\n",
    "\n",
    "\n",
    "### What You Are Being Asked To Do\n",
    "\n",
    "(A version of this is posted on **Discord**)\n",
    "\n",
    "The file `sample_submission.csv` has examples of the format that the evaluated text should display the results. This includes the text_id with the cohesion, syntax, vocabulary, phraseology, grammer and conventions scores.\n",
    "\n",
    "An example of what you are being asked to do:\n",
    "* give your model the text of a english language learner (8-12th grade) which the model assigns the  **cohesion, syntax, vocabulary, phraseology, grammer and conventions scores**. (each score 1-5)\n",
    "* in the competition, **Kaggle** will take the scores and compare them to the human determined scores\n",
    "* Then the model will get scored based on how close it is to the human ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ece326-df7e-418d-b366-4184595bd4f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download The Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aaac489-97a5-47cc-a2d9-38be6df8b43f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One way to download the data is through Tensorflow's Datasets repository\n",
    "# Data is stored at:\n",
    "#    ~/tensorflow_datasets/wikipedia_toxicity_subtypes/\n",
    "#    ~/tensorflow_datasets/civil_comments/CivilComments/\n",
    "# Dataset sizes are:\n",
    "#    2 Gb - wikipedia_toxicity_subtypes\n",
    "#    1 Gb - civil_comments\n",
    "# This code cell takes about 5-10 minutes to execute\n",
    "# You only need to run this code cell once. If you run it again it doesn't\n",
    "#     do anything since the datasets have already been downloaded\n",
    "\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "#ds_wikipedia_comments = tfds.load('wikipedia_toxicity_subtypes')\n",
    "#ds_comment_bias = tfds.load('civil_comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e87467e-8f48-43c9-824d-8ec09c36d64d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code from: https://www.tensorflow.org/datasets/overview#tfdsas_dataframe\n",
    "\n",
    "#import tensorflow_datasets as tfds\n",
    "#import pandas\n",
    "\n",
    "# working with DataFrames\n",
    "#dset, info = tfds.load('wikipedia_toxicity_subtypes', with_info=True)\n",
    "#dframe = tfds.as_dataframe(dset[\"train\"].take(1000), info) # only takes the first 1000 data samples\n",
    "#dframe = tfds.as_dataframe(dset[\"train\"], info) # takes all the data into memory (takes a while)\n",
    "\n",
    "# display first few rows & last few rows\n",
    "#dframe.head()\n",
    "#dframe.tail()\n",
    "\n",
    "# display column names\n",
    "#dframe.columns\n",
    "\n",
    "# statistic summary of the data\n",
    "#dframe.describe()\n",
    "\n",
    "# selecting the \"text\" column (these do the same thing)\n",
    "#dframe[\"text\"]\n",
    "#dframe.text\n",
    "\n",
    "# selecting the \"insult\" column (these do the same thing)\n",
    "#dframe[\"insult\"]\n",
    "#dframe.insult\n",
    "\n",
    "# getting the comment text from the 10th comment in the dataset\n",
    "#dframe[\"text\"][9]\n",
    "\n",
    "# selecting rows 10 to 15\n",
    "#dframe[10:16]\n",
    "\n",
    "# selecting all the comments that are labelled as an insult\n",
    "#dframe[dframe[\"insult\"] > 0]\n",
    "\n",
    "# fancy advanced:\n",
    "#    selects the comments where column \"E\" has either the value of \"two\" or \"four\"\n",
    "#dframe = tfds.as_dataframe(dset[\"train\"].take(6), info) # only takes the first 6 data samples\n",
    "#dframe2 = dframe.copy()\n",
    "#dframe2[\"E\"] = [\"one\", \"one\", \"two\", \"three\", \"four\", \"three\"]\n",
    "#dframe2[dframe2[\"E\"].isin([\"two\", \"four\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f49281-4ab4-4437-9446-9e154bbd3e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading csv files attached\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "pd.set_option('display.max_rows', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d6f873c-a23f-471c-bbc5-14ef4102522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING BAD DATA\n",
    "count = 0\n",
    "for a in train[\"cohesion\"]:\n",
    "    try:\n",
    "        z = float(a)\n",
    "    except:\n",
    "        train = train.drop([count])\n",
    "    count+=1\n",
    "count = 0\n",
    "for a in train[\"vocabulary\"]:\n",
    "    try:\n",
    "        z = float(a)\n",
    "    except:\n",
    "        train = train.drop([count])\n",
    "    count+= 1\n",
    "count = 0\n",
    "for a in train[\"syntax\"]:\n",
    "    try:\n",
    "        z = float(a)\n",
    "    except:\n",
    "        train = train.drop([count])\n",
    "    count+= 1\n",
    "count = 0\n",
    "for a in train[\"phraseology\"]:\n",
    "    try:\n",
    "        z = float(a)\n",
    "    except:\n",
    "        train = train.drop([count])\n",
    "    count+= 1\n",
    "count = 0\n",
    "for a in train[\"grammar\"]:\n",
    "    try:\n",
    "        z = float(a)\n",
    "    except:\n",
    "        train = train.drop([count])\n",
    "    count+= 1\n",
    "count = 0\n",
    "for a in train[\"conventions\"]:\n",
    "    try:\n",
    "        z = float(a)\n",
    "    except:\n",
    "        train = train.drop([count])\n",
    "    count+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574fe49c-0488-46f7-8073-36b71989aac2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Task: Extract Features From Dataset   (40 Marks)\n",
    "\n",
    "Used **NLTK**  and **TF-IDF** to extract **features** from the **Essays** dataset.\\\n",
    "The **features** will be used to train  **SVM** to identify writing level.\n",
    "\n",
    "**features** to extract:\\\n",
    "The frequency distribution is vectorized with tf-idf giving a large amount of features\n",
    "\n",
    "\n",
    "### Transforming Data Into Features\n",
    "\n",
    "We represent the data as matrices/vectors. So we are transforming the dataset into a matrix representation. None of the models accept text input! Example:\\\n",
    "`X = [[0, 0], [1, 3], [2, 0], [3, 1]]`\\\n",
    "`Y = [0, 1, 2, 3]`\n",
    "\n",
    "### Rubric\n",
    "\n",
    "We will be evaluating this section in part by how clever your choice of features were (and that you were able to extract them).\n",
    "Simple sets of features may not be as informative as complex setds of features, but simple features are easier to extract from a dataset compared to complex features.\n",
    "\n",
    "A breakdown of the marking for this task:\n",
    "* [**10 marks**] basic features gathered (trivial)\n",
    "* [**25 marks**] quality features gathered (advanced), corresponding to unusual features or clever features most would not have considered\n",
    "* [**5 marks**] formatting the features and output correctly so it can be used immediately downstream for the machine learning classifiers without any further preprocessing needing to be done at that stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101614c",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    <p>Extract at least one or two features before implementing any of the models.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcbeb03d-2d9c-462e-946a-6739a051fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: check if a word is in a list of words\n",
    "#list_of_words = [\"house\", \"hat\", \"war\"]\n",
    "#word = \"hat\"\n",
    "#print(\"Is 'hat' in the wordlist?\", word in list_of_words)\n",
    "\n",
    "#word = \"Hat\"\n",
    "#print(\"Is 'Hat' in the wordlist?\", word in list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbad27fd-292e-46c7-839f-354ac366919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: check if a character is in a list of characters\n",
    "#character_string = '?.\",!@$%^&*()\\n' # using a String as if it were a list\n",
    "#character = \"?\"\n",
    "#print(\"Is '?' in the characterlist?\", character in character_string)\n",
    "\n",
    "#character = \"\\n\"\n",
    "#print(\"Is '\\\\n' (newline) in the characterlist?\", character in character_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c35dae9c-6929-4568-8e9e-ce3e1dd750b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: for more code fragments that may be useful\n",
    "#               check the Discord server (I will not be adding new snippets to this Task here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122e537-b8bf-4ffb-8a7b-b4ce3df3a7ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that extracts features from the dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19043b9-576b-4e6f-a437-2d043eed78e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Old Vocab test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea231bf-3fee-486d-a0ac-5414717fd61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features for VOCAB of TRAINING DATA\n",
    "#\n",
    "#result = []\n",
    "#\n",
    "#tokenize full_text into words\n",
    "#for text in train[\"full_text\"]:\n",
    "#    total_length = 0\n",
    "#    max_word_length = 0\n",
    "#    text = nltk.tokenize.word_tokenize(text)\n",
    "#    \n",
    "#    for word in text:\n",
    "#        #get word length total\n",
    "#        total_length += len(word)\n",
    "#\n",
    "#        #get max word length\n",
    "#        if len(word) > max_word_length:\n",
    "#            max_word_length = len(word)\n",
    "#        \n",
    "#    # get word length average\n",
    "#    word_length_average = total_length/len(text)\n",
    "#    \n",
    "#    result.append([max_word_length, word_length_average])\n",
    "#vocab_features_train = pd.DataFrame(result, columns = ['Max Word Length', 'Average Word Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd12800e-75e3-414a-8cfd-87f62be8b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features for VOCAB of TESTING DATA\n",
    "\n",
    "#tokenize full_text into words\n",
    "#for text in test[\"full_text\"]:\n",
    "#    total_length = 0\n",
    "#    max_word_length = 0\n",
    "#    text = nltk.tokenize.word_tokenize(text)\n",
    "#    \n",
    "#    for word in text:\n",
    "#        #get word length total\n",
    "#        total_length += len(word)\n",
    "#\n",
    "#        #get max word length\n",
    "#        if len(word) > max_word_length:\n",
    "#            max_word_length = len(word)\n",
    "#        \n",
    "#    # get word length average\n",
    "#    word_length_average = total_length/len(text)\n",
    "#    \n",
    "#    result.append([max_word_length, word_length_average])\n",
    "#vocab_features_test = pd.DataFrame(result, columns = ['Max Word Length', 'Average Word Length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba0579-5041-4b0d-abe2-0b78f2446f80",
   "metadata": {
    "tags": []
   },
   "source": [
    "### New TD-IDF Generated Features\n",
    "Taken from: https://www.kaggle.com/code/tracyporter/ell-nlp-multioutput/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0659784a-4b78-47bd-b4be-9b165fe6b6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I think that students would benefit from learn...\n",
       "1       When a problem is a change you have to let it ...\n",
       "2       Dear, Principal\\n\\nIf u change the school poli...\n",
       "3       The best time in life is when you become yours...\n",
       "4       Small act of kindness can impact in other peop...\n",
       "                              ...                        \n",
       "3909    Many people disagree with Albert Schweitzer's ...\n",
       "3910    Do you think that failure is the main thing fo...\n",
       "0       when a person has no experience on a job their...\n",
       "1       Do you think students would benefit from being...\n",
       "2       Thomas Jefferson once states that \"it is wonde...\n",
       "Name: full_text, Length: 3912, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature headings\n",
    "features = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar',  'conventions']\n",
    "\n",
    "target = train[features]\n",
    "\n",
    "# text of both train and test files\n",
    "text_train = train['full_text']\n",
    "text_test = test['full_text']\n",
    "text = pd.concat([text_train, text_test])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6965b1f5-9343-484a-b037-738260786ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the text to be lowercase without any symbols or punctioation\n",
    "\n",
    "text = text.str.lower()\n",
    "text = text.apply(lambda x : re.sub(\"[^a-z]\\s\",\"\",x) )\n",
    "text = text.str.replace(\"#\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ce33ade-bdde-44b8-895c-2a90715ef047",
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophe_dict = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0e7a4ed-bc8e-4c56-a3db-462ae3c0a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to replace apostrophe dictionary with the full two words\n",
    "def lookup_dict(txt, dictionary):\n",
    "    for word in txt.split():\n",
    "        if word.lower() in dictionary:\n",
    "            if word.lower() in txt.split():\n",
    "                txt = txt.replace(word, dictionary[word.lower()])\n",
    "    return txt\n",
    "text = text.apply(lambda x: lookup_dict(x,apostrophe_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17e13991-6aef-4fc8-8436-7705a062331a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'to': 70704, 'the': 52872, 'and': 40272, 'you': 36163, 'a': 35898, 'that': 29494, 'is': 29015, 'in': 26879, 'they': 24149, 'not': 23719, ...})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting frequency distribution\n",
    "fdist = nltk.probability.FreqDist()\n",
    "for x in text:\n",
    "    fdist += nltk.probability.FreqDist(word for word in nltk.tokenize.word_tokenize(x))\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "693ac523-9021-4be6-92a6-7a867c3a1f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i think that students would benefit from learn...\n",
       "1       when a problem is a change you have to let it ...\n",
       "2       u change the school policy of having a grade b...\n",
       "3       the best time in life is when you become yours...\n",
       "4       small act of kindness can impact in other peop...\n",
       "                              ...                        \n",
       "3907    many people disagree with albert is not the ma...\n",
       "3908    do you think that failure is the main thing fo...\n",
       "3909    when a person has no experience on a job their...\n",
       "3910    do you think students would benefit from being...\n",
       "3911    thomas jefferson once states that is wonderful...\n",
       "Length: 3912, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove words of one count\n",
    "# most likely mistakes\n",
    "\n",
    "v = text.str.split().tolist()\n",
    "\n",
    "text = [' '.join([y for y in x if fdist[y] > 1]) for x in v]\n",
    "text = pd.Series(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330bbc7-9864-4cfb-93d1-fc5078300947",
   "metadata": {},
   "source": [
    "#### Generating features using TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16bb924c-eb99-4e96-a0e7-7ebab13d8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# setting up input and output for SVM\n",
    "y = target\n",
    "X = text[: len(train)]\n",
    "X_test = text[len(train) :]\n",
    "X = X.tolist()\n",
    "X_test = X_test.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a674f06-1ace-4c1b-8aa0-dae6e4c30e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizoring using tf-idf\n",
    "# generating features\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.5, min_df=0.01)\n",
    "\n",
    "X = vectorizer.fit_transform(X)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eefcfa8d-8b3f-4d6d-936f-6db9f7bafda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b496bf53-1b24-4b5f-a9da-cc23b8f74a00",
   "metadata": {},
   "source": [
    "----\n",
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    Classifiers take two arrays as input: <strong>array X</strong> and <strong>array y</strong>.</br>\n",
    "    <strong>array X</strong> has shape <tt>(number_of_samples, number_of_features)</tt> containing the training samples feature data</br>\n",
    "    <strong>array y</strong> of class labels/outputs (strings or integers) has shape <tt>(number_of_samples)</tt></p>\n",
    "    <p></p>\n",
    "    <p style=\"text-indent:0px\"><tt>print(photos.shape, labels.shape)</br>\n",
    "    num_samples = labels.shape[0]<br>\n",
    "    x = np.reshape(photos, (num_samples, -1))<tt></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95089c7a-f618-4671-8e57-9a477f56a315",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision Trees For Classification\n",
    "\n",
    "Example code for a **Decision Tree** performing classification. The **Decision Tree** model is predicting one category from a set of categories, such as which genre a film belongs to (`Horror`, `Comedy`, `Action`, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8560355a-3cd8-4137-92b1-21f02198c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "#from sklearn import tree\n",
    "\n",
    "#X = [[0, 0, -1], [1, 1, 1], [1, 10, 9], [-3, 0, 33]]\n",
    "#Y = [0, 1, 4, 1]\n",
    "\n",
    "# DecisionTreeClassifier takes as input two arrays: X & Y\n",
    "#    an array X, sparse or dense, of shape (number_of_samples, number_of_features) holding the training samples\n",
    "#    and an array Y of integer values, of shape (number_of_samples) holding the class labels for the training samples\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# train the decision tree classifier model\n",
    "#clf = clf.fit(X, Y)\n",
    "\n",
    "# after being fitted, predict from a new set of samples\n",
    "#clf.predict([[2., 2., 10.]])\n",
    "\n",
    "\n",
    "# plot a visualization of the decision tree\n",
    "#tree.plot_tree(clf)\n",
    "\n",
    "\n",
    "# a text visualization of the decision tree\n",
    "#from sklearn.tree import export_text\n",
    "#text_tree = export_text(clf, feature_names=[\"First Feature\", \"Height Feature\", \"Salary Feature\"])\n",
    "#print(\"Text visualization of decision tree:\\n\", text_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df590be3-a107-4399-b79e-ebfca3b6cf15",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision Trees For Regression\n",
    "\n",
    "Regression using **Decision Trees** is [found here](https://scikit-learn.org/stable/modules/tree.html#regression).\n",
    "\n",
    "Example code of a **Decision Tree** for regression (where the **Decision Tree** model is predicting a continuous value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b8db8bf-3ab7-4612-8fd1-4aa1bd791e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# code from https://scikit-learn.org/stable/modules/tree.html#regression\n",
    "\n",
    "#from sklearn import tree\n",
    "\n",
    "#X = [[0, 0], [2, 2]]\n",
    "#y = [0.5, 2.5]\n",
    "\n",
    "\n",
    "#clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "# train the decision tree regression model\n",
    "#clf = clf.fit(X, y)\n",
    "\n",
    "# after being fitted, predict from a new set of samples\n",
    "#clf.predict([[1, 1]])\n",
    "\n",
    "# plot a visualization of the decision tree\n",
    "#tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1689ef-d3d7-443f-844e-abb627da153f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Decision Tree classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b54a755e-41ef-4a0d-b0fc-85666a37febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "#raise NotImplementedError() # Remove this after you have started implementing your code below\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Evaluate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3977e62-f633-4058-bdca-2911a1fe61cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "## Task: SVM Classifier   (5 Marks)\n",
    "\n",
    "Build an [SVM classifier](https://scikit-learn.org/stable/modules/svm.html#classification) that identifies toxic comments.\\\n",
    "Use the **SVM**'s default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eae63000-79a2-49ec-9de4-1c231cc3fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/svm.html#classification\n",
    "\n",
    "#from sklearn import svm\n",
    "\n",
    "# the dataset  X:features, y:output values we are trying to predict\n",
    "#X = [[0.0, 0], [1.2, 1]]\n",
    "#y = [0, 1]\n",
    "\n",
    "#clf = svm.SVC()\n",
    "\n",
    "# train the model\n",
    "#clf.fit(X, y)\n",
    "\n",
    "# after being fitted, predict new values\n",
    "#clf.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6eaf6-02da-470a-b435-91e6918ea685",
   "metadata": {},
   "source": [
    "**SVM** for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7965fc32-0c4e-45ac-b29b-7148463a6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/svm.html#regression\n",
    "\n",
    "#from sklearn import svm\n",
    "\n",
    "# the dataset  X:features, y:output values we are trying to predict\n",
    "#X = [[0, 0], [1, 1]]\n",
    "#y = [0, 1.2]\n",
    "\n",
    "#clf = svm.SVR()\n",
    "\n",
    "# train the model\n",
    "#clf.fit(X, y)\n",
    "\n",
    "# after being fitted, predict new values\n",
    "#clf.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13330c-177a-4700-9fe8-b9b623ccfa45",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements an SVM classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326e58d-fdd3-46c3-b7af-7dfc49ac103c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Old SVM With Old Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3c5a384-6e2b-4724-9f8c-e9fc623773a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "#\n",
    "# Train the model\n",
    "#from sklearn import svm\n",
    "#\n",
    "# the dataset  X:features, y:output values we are trying to predict\n",
    "#X = vocab_features_train.values.tolist()\n",
    "#y = train[\"vocabulary\"].values.tolist()\n",
    "#\n",
    "#clf = svm.SVR(kernel='poly')\n",
    "#\n",
    "# train the model\n",
    "#clf.fit(X, y)\n",
    "#\n",
    "# after being fitted, predict new values\n",
    "#results = clf.predict([[x,y] for x,y in vocab_features_train.values.tolist()])\n",
    "#print(results,flush=True)\n",
    "#temp = []\n",
    "#for x in results:\n",
    "#    temp.append(round(x*2)/2)\n",
    "#results = temp\n",
    "# Evaluate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc5e83-193c-4f66-8c18-64c77d795fdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### Cross Validation Of A Dataset Of SVM\n",
    "\n",
    "The following example code demonstrates using the builtin cross validation module from the [**Scikit-Learn** library](https://scikit-learn.org/stable/modules/cross_validation.html).\\\n",
    "You will likely use a variation of the following code for all of the models you will be evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb83250e-6489-4cff-9ead-63693e2da411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = np.array(vocab_features_train, dtype=float)\n",
    "#y = np.array(train['vocabulary'], dtype=float)\n",
    "\n",
    "#X = vocab_features_train\n",
    "#y = train['vocabulary']\n",
    "\n",
    "#X.shape, y.shape # shape displays the dimensions of the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06f0e64a-f8d7-4481-b8c7-793f4a58ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.007, random_state=42)\n",
    "\n",
    "\n",
    "#clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "\n",
    "#score = clf.score(X_test, y_test)\n",
    "\n",
    "#print(\"The performance of one run of the SVM model:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a778fc0-c621-47fc-9ba2-cd119a08b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#clf = svm.SVR(kernel='linear', C=1, random_state=42)\n",
    "\n",
    "#scores = cross_val_score(clf, X, y, cv=2)\n",
    "#print(\"Scores for the 5 runs of the SVM model:\", scores)\n",
    "#print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d327ef45-8663-44d0-89af-23678e49e4f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cross Validation with SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8746d89-53c7-4ea4-9cf0-d3d5aa0fbdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of one run of the SVM model: 0.8683084411466719\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "clf = MultiOutputRegressor(svm.SVR()).fit(X, y)\n",
    "\n",
    "score = clf.score(X, y)\n",
    "\n",
    "print(\"The performance of one run of the SVM model:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a99fd08-e679-4b8e-9426-750727965348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the 5 runs of the SVM model: [0.2043183  0.22164647 0.20201111 0.23256935 0.21464616]\n",
      "0.22 accuracy with a standard deviation of 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Scores for the 5 runs of the SVM model:\", scores)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbd51d04-4ab7-4552-973d-c14e963eb615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8752967 , 2.66967502, 3.27707537, 3.09959794, 2.7080656 ,\n",
       "        2.63712166],\n",
       "       [3.11647148, 2.84580193, 2.89114212, 2.6167223 , 2.58304548,\n",
       "        3.00077795],\n",
       "       [3.54040148, 3.46766088, 3.64180325, 3.49960481, 3.37827924,\n",
       "        3.39248726]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a6430d2-def8-4da9-ba7b-6701e1d942f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to Quiz #4 for help with n-gram language models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f13fe6-37d1-4d2b-afb5-0d9f4e03868c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Tri-gram Language Model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9abf8031-12c5-46cc-9b4f-bcbda5ad0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "#raise NotImplementedError() # Remove this after you have started implementing your code below\n",
    "\n",
    "# Create a Trigram language model\n",
    "\n",
    "\n",
    "# Create a Bigram language model\n",
    "\n",
    "\n",
    "# Create a Unigram language model\n",
    "\n",
    "\n",
    "# Compute the probability a comment is toxic\n",
    "\n",
    "\n",
    "# Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8bd7821-c669-475c-937e-b60a97e287c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "# Classification\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = [[0, 0], [1, 1]]\n",
    "Y = [0, 1]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e7c905-fcc8-4b00-bc48-dc1ba644ddca",
   "metadata": {},
   "source": [
    "**Random Forest** for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64a00f27-fffd-4b01-839b-713769b6bca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.32987858]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "# Regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "regr.fit(X, y)\n",
    "\n",
    "print(regr.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f03d51-a57b-4ba2-96e8-3872b1dff3bf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Random Forest Classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e682a15b-88ef-42f1-bd3b-7846fdafaf4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# YOUR CODE IN THIS CELL\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "#raise NotImplementedError() # Remove this after you have started implementing your code below\n",
    "\n",
    "# Train the model\n",
    "\n",
    "# Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd90891-aa2d-42d6-9f2b-99f2aba7fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Load some example data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "# The Ensemble classifier\n",
    "# 'estimator' is another name for 'model' or 'learner'\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "                        voting='soft',\n",
    "                        weights=[2, 1, 2])\n",
    "\n",
    "# train the individual classifiers first\n",
    "clf1 = clf1.fit(X, y)\n",
    "clf2 = clf2.fit(X, y)\n",
    "clf3 = clf3.fit(X, y)\n",
    "# then train the ensemble of the trained classifiers (clf1, clf2, & clf3)\n",
    "eclf = eclf.fit(X, y)\n",
    "\n",
    "# make predictions\n",
    "print(\"Ensemble classifier's predictions:\\n\", eclf.predict(X))\n",
    "print(\"\\nThe resulting dimensions of the Ensemble classifier:\", eclf.transform(X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8d8d4-b7c0-4b45-bb6b-2716f9304d24",
   "metadata": {},
   "source": [
    "A **Voting Ensemble** example for regression is [found here](https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd82000-bbc5-4fa0-b41b-5d62c1907f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Loading some example data\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# Training individual models\n",
    "reg1 = GradientBoostingRegressor(random_state=1)\n",
    "reg2 = RandomForestRegressor(random_state=1)\n",
    "reg3 = LinearRegression()\n",
    "\n",
    "# create an ensemble from the individual models\n",
    "ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "\n",
    "ereg = ereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead89e2-b8a8-4fc5-b1b3-812c890b2ab3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Voting Ensemble classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20168e1-9721-47c3-8854-aeb5876abee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "raise NotImplementedError() # Remove this after you have started implementing your code below\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db17d7-1593-4fc5-b3d2-40d06bc21f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# from   https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "########################\n",
    "### SET UP THE DATASET\n",
    "########################\n",
    "\n",
    "# Uses the IMDB Movie Reviews dataset\n",
    "# Split the training set into 60% and 40% to get\n",
    "#     15,000 training examples\n",
    "#     10,000 examples for validation\n",
    "#     25,000 testing examples\n",
    "train_data, validation_data, test_data = tfds.load( name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)\n",
    "\n",
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "\n",
    "# print first 10 examples\n",
    "print(train_examples_batch)\n",
    "# print the first 10 labels\n",
    "train_labels_batch\n",
    "\n",
    "\n",
    "####################################\n",
    "### SET UP THE NEURAL NETWORK MODEL\n",
    "####################################\n",
    "\n",
    "# create a Keras layer that uses a TensorFlow Hub model to embed the sentences\n",
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])\n",
    "\n",
    "# build the full model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# configure the model to use an optimizer and a loss function\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "####################################\n",
    "### TRAIN THE NEURAL NETWORK MODEL\n",
    "####################################\n",
    "\n",
    "# Train the model for 10 epochs in mini-batches of 512 samples\n",
    "# This is 10 iterations (epochs) over all samples in the x_train and y_train tensors\n",
    "# While training, monitor the model's loss and accuracy on the 10,000 samples from the validation set\n",
    "history = model.fit(train_data.shuffle(10000).batch(512),\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_data.batch(512),\n",
    "                    verbose=1)\n",
    "\n",
    "\n",
    "######################################\n",
    "### EVALUATE THE NEURAL NETWORK MODEL\n",
    "######################################\n",
    "\n",
    "# Evaluate the model\n",
    "# Two values will be returned:\n",
    "#    Loss (a number which represents our error, lower values are better)\n",
    "#    Accuracy\n",
    "results = model.evaluate(test_data.batch(512), verbose=2)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a32125-fb29-465f-bc1a-094f39b4f6f9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Neural Network.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89211ebe-e5d2-4692-8619-a4c8618357d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "raise NotImplementedError() # Remove this after you have started implementing your code below\n",
    "\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35b722-5c89-479f-b75b-c6835db33a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "\n",
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, Y, np.unique(Y))\n",
    "\n",
    "print(clf_pf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753557-4871-4dca-ad24-9b751332bff7",
   "metadata": {},
   "source": [
    "### Regression (Linear Model)\n",
    "\n",
    "For regression, use a **Linear Regression** model instead of *Naive Bayes*.\\\n",
    "A succinct overview of using a [linear model to detect diabetes](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py) provides a good explanation of an end-to-end experimental workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1867806-8b86-4704-8216-79b44569a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/linear_model.html\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# train the model with data\n",
    "reg.fit([[0, 0], [1, 1], [2, 2]],\n",
    "        [0, 1, 2])\n",
    "\n",
    "# make predictions\n",
    "prediction = reg.predict([[-0.8, -1]])\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf1896d-f3c0-48e1-a640-6f3ee19e471d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Naive Bayes Classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48248840-0218-4df6-be5e-a6726206a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "raise NotImplementedError() # Remove this after you have started implementing your code below\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfbb7f7-1b5f-43c0-97ae-47d7813851c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task: Evaluation   (10 Marks)\n",
    "\n",
    "\n",
    "Model will be *trained* on the **training data**.\\\n",
    "Model will be *evaluated* on the **test data**.\n",
    "\n",
    "<font color=red>**TBD**.<font color=black> The below is *not* the final evaluation method but the one used in the **Kaggle** competition.\n",
    "\n",
    "<font color=lightgray>\n",
    "\n",
    "The evaluation description for the original **Idenifying Toxic Comments** task needs to be updated.\n",
    "    \n",
    "> Submissions are evaluated on the **mean column-wise ROC AUC**.\\\n",
    "> In other words, the score is the **average of the individual AUCs of each predicted column**.\n",
    "> \n",
    "> **Submission File**\n",
    "> \n",
    "> For each id in the test set, you must predict a probability for each of the six possible types of comment toxicity (*toxic, severetoxic, obscene, threat, insult, identityhate*). The columns must be in the same order as shown below. The file should contain a header and have the following format:\n",
    "> \n",
    "> \t\tid,toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
    "> \t\t00001cee341fdb12,0.5,0.5,0.5,0.5,0.5,0.5\n",
    "> \t\t0000247867823ef7,0.5,0.5,0.5,0.5,0.5,0.5\n",
    "> \t\t...\n",
    "> \t\tetc.\n",
    "\n",
    "    \n",
    "<font color=black>\n",
    "\n",
    "### How To Evaluate A Machine Learning Model\n",
    "\n",
    "We will assign a toxicity score to two comments where one of the comments are determined by humans to be more toxic than the other comment.\n",
    "The performance of a model is measured by how many of the comment pairs agree with human rankings.\n",
    "\n",
    "For example, **Comment 1** (from `validation_data.csv`) is given a score of 1.65 &\n",
    "**Comment 2** is given a score of 76, resulting in **Comment 2** being more toxic than **Comment 1**. If this matches the human assessment then we score 1/1. If not, then the score is 0/1.\n",
    "    \n",
    "From the [task's description on **Kaggle**](https://www.kaggle.com/c/jigsaw-toxic-severity-rating/overview/evaluation):\n",
    "> *For each of the approximately 200,000 pair ratings in the ground truth test data, we use your predicted toxicity score to rank the comment pair. The pair receives a 1 if this ranking matches the annotator ranking, or 0 if it does not match.*\n",
    "    \n",
    "The data used in the evaluation comes from `validation_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54821a58-ea33-47f7-a3be-28ed15357a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "\n",
    "# keep track of how many comment pairs we correctly rank\n",
    "#total_correct_comment_pair_rankings = 0\n",
    "\n",
    "# get next pair of comments from validation_data.csv\n",
    "# NOTE: comment1 is from the column corresponding to \"LESS TOXIC\"\n",
    "#       comment2 is from the column corresponding to \"MORE TOXIC\"\n",
    "#comment1 = \"Comment from Wikipedia! (less toxic comment)\"\n",
    "#comment2 = \"ANOTHER Comment from Wikipedia! Swear word: bA$$ (more toxic comment)\"\n",
    "\n",
    "# convert the comment's text into a feature vector e.g., [0, 0, 2.51, 1, ...]\n",
    "#comment1_features = extract_features(comment1)\n",
    "#comment2_features = extract_features(comment2)\n",
    "\n",
    "# compute the toxicity score of each comment\n",
    "#toxicicity_score_of_comment1 = some_model.predict(comment1_features)\n",
    "#toxicicity_score_of_comment2 = some_model.predict(comment2_features)\n",
    "\n",
    "#if toxicicity_score_of_comment2 > toxicicity_score_of_comment1:\n",
    "#    total_correct_comment_pair_rankings = total_correct_comment_pair_rankings + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c5afb-aed8-4287-b637-227c85e004d4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code for evaluating a model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b746513-cfa0-4cd6-847b-b2d301e4d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission of predictions\n",
    "# rounding predictions to increments of .5 with list comprehension\n",
    "submission = pd.DataFrame()\n",
    "submission['cohesion'] = [round(x*2)/2 for x in predictions[:,0]]\n",
    "submission['syntax'] =  [round(x*2)/2 for x in predictions[:,1]]\n",
    "submission['vocabulary'] =  [round(x*2)/2 for x in predictions[:,2]]\n",
    "submission['phraseology'] =  [round(x*2)/2 for x in predictions[:,3]]\n",
    "submission['grammar'] =  [round(x*2)/2 for x in predictions[:,4]]\n",
    "submission['conventions'] =  [round(x*2)/2 for x in predictions[:,5]]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a47b4-89e0-43e2-b05d-9846b1e8049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False) # writing data to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17568c-6bc9-4f8b-af7c-a5e0745a569c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "----\n",
    "# Task: Project Report   \n",
    "\n",
    "The total marks for all of the sections below is **80 Marks**.\n",
    "\n",
    "This section corresponds to the write-up of the project. Your write-up is to be included within this **Jupyter Notebook** below (the code for this assignment is in the code cells above).\\\n",
    "The **Project Report** will consist of a few sections that each discuss a different stage of the end-to-end experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cdacf-58cd-4226-b9d0-f5081a9d196f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview    (5 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the problem/task you are addressing\n",
    "* provide concrete examples of the problem\n",
    "* why the problem is worth the time and effort trying to solve\n",
    "* compare the task with other tasks that are similar\n",
    "\n",
    "The following are optional:\n",
    "* *Related Work* i.e., what have other people tried\n",
    "* historical background of the problem\n",
    "* discuss strategies used in other tasks that are similar to **Toxic Comment Identification**\n",
    "* discuss the differences with those tasks that are similar to **Toxic Comment Identification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3cf30-88c1-4bac-b854-ee03add22f8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset    (5 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the dataset's size\n",
    "* languages dataset contains\n",
    "* anything unusual about the data\n",
    "* how representative the dataset is of everyday communication\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbcaf12-1c62-4a31-a18b-8d4036f17590",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Features    (5 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the features that were extracted\n",
    "* the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa3979f-0844-4cc9-9029-0bae2e1af800",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models    (5 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the models used\n",
    "* any specific parameters, configuration, or settings of each model\n",
    "* any differences in how each model was trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6adfef-dd91-4803-b341-fae364ee2370",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation    (5 Marks)\n",
    "\n",
    "This section discusses:\n",
    "* how you evaluated the models in order to compare their relative performance\n",
    "* evaluating models based on *overall performance*\n",
    "* use visuals, tables, charts, graphs, etc. to communicate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8ed7f-317d-4778-8ac9-96ca60248877",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Discussion    (15 Marks)\n",
    " \n",
    "Compare the performance of the above models on **Identifying Toxic Comments**.\\\n",
    "Use visuals, charts, graphs, etc. to communicate your results.\n",
    "\n",
    "Discuss:\n",
    "* your findings in general\n",
    "* compare the performance of the various models (was the performance what you expected?)\n",
    "* which system performed best? why?\n",
    "* which system had the worst performance? why?\n",
    "* discuss the reasons which lead to the results from the evaluation\n",
    "* provide some ideas you would like to have tried (provided you had more time or resources) that could potentially improve the performance of the models or a question that you were interested in exploring (i.e., *Future Work*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac2106-1c27-468d-99d7-299992efc546",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h1>YOUR PROJECT REPORT BEGINS BELOW THIS CELL</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6649d70c-a699-4246-b5c1-751abf71a6ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "**INFORMATION**\\\n",
    "Student Name: *Hunter Klassen*\\\n",
    "Student ID: *300174049*\\\n",
    "Student UFV Email: *Hunter.Klassen@student.ufv.ca*\n",
    "\n",
    "# Overview\n",
    "\n",
    "The project I have worked on is the Kaggle competition problem 'Feedback Prize - English Language Learning'. This competition tasked me with rating cohesion, syntax, vocabulary, phraseology, grammar, and conventions based on the training data given where a rating of 1.0-5.0 in 0.5 increments was given for each section assosiated with an essay of writing from a grade 8-12 level. for this test text:\n",
    "\n",
    "*\"when a person has no experience on a job their is always going to be good people to help you and try to explane the job you need to get done in life you were not born with knowing everything. Life is bassicly about learing new things every single day even though without experience because life is simple and we must live happy and around with the people we love. When a person thinks they know everything in life they dont do good because they trying to make the other person less then others you must be kind to those the dont have experience because you may not know some day you will go to a different country. When you dont know anyting because you not from their so you going to need help from others to explain you about the culture or how to eat a food because you have to no experience on the new country. You must help a person the has no experience because maybe you may need help from the person the you didnt want to help.\\n\\nyes, even thought you may not have experience in the type of job you seek,you can learn and teach others.\\n\\nIf you dont have experence in a restaurant for the job you seek for you will learn. For example a person the has no experence working in a restaurant,the only place they will offer you would be to be a diswasher. But you want to dream big because everytime a person has big dreams they can learn the job whereever, you want to be like a cooking person or a kitchen manager. In a job there is always going to be people the they dont want to see you in a better place because they may think you dont deserve to be there but you the only one the knows how hard you being working to achieve your dream .In life you always going to have proof without experience to see how good you are to learn a new job in the kitchen so if you can learn quick. They can give you a good place for you teach others the has no experience.\\n\\nMy dad has always talk with my cousins that when their is no experience you can always learn and fight for what you want. When my cosuin came to America he wanted to play travel soccer, he went to tryout but the coach told him the has any experience of talking english so he wouldn't make it. But later on he learn how to speak then, he went to tryout for fc virginia he made it also everyone was talking about him because hes a great soccer player also, hes a great person. Then he came to the house and thanks my dad because of the edvice he gave to him the even though you dont have experience,you can always learn and fight for you goals. My dad is man the wants the best for hes family because when he was a kid he wanted to be a loyer but it was hard for hes parents because they were really poor and the corruption was really bad in the country.\\n\\nIn every job their is always going to be a person with no experience. For example people with no experience those are the ones the learn the job and when they learn the job very well they always try not to make a mistake because thay want to get the job done with quality. Because everytime you do a job for someone else they want to see good quality on you before they give the kind of job they want you to get done for them. The people the has no experience in a job that doesnt make them a less person because we all are humans and we must have the same equal rights. we all know the everytime you aplied for a job the first thing they asked you is about if you have experience but its okay to say no because they can teach you and you can get it fast.\\n\\nI think yes, you can be a good candidate to be hire without no experience because every person in the world needs to have a opportunity to try something new. People today in life they dont need to have experience to go find a job why because today in every work you get one week of train which people can learn the job just in one week. Because they will practice the job and every time they get practice they will going to get better and better. Practices makes everything better so dont be scared to applied for job only because it says you must have experience no just go believe in youself. If you believe in you everything will be good in like ad you will be going great just be you even though you have experience or not we all deserve a chance.\"*\n",
    "\n",
    "There will be a value for cohesion, syntax, vocabulary, phraseology, grammar, and conventions. potentially these values could be:\\\n",
    "cohesion = 3.0\\\n",
    "syntax = 2.5\\\n",
    "vocabulary = 3.5\\\n",
    "phraseology = 3.0\\\n",
    "grammar = 3.0\\\n",
    "conventions = 2.5\n",
    "---\n",
    "**Application**\n",
    "\n",
    "This can help students get feedback in particular areas of their writing skill. With particular enphasise on English Language Learners trying to hone their skills. With automated feedback, getting constructive feedback instantly enables writers to write more.\\\n",
    "This automated feedback is also unbaised and consistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661b9913-05e0-4115-be2c-f7ed21fe049f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset\n",
    "\n",
    "The data being used is the one provided with the competition listed at the top. The data is a table consisting of the 3912 full texts along with the rating of each section for every text. The data came formated in csv and was easily convertable to the pandas dataframe object. This data came with errors in both the text with missing spaces and random sumbols but also text in the cell of what should be the rating for a particular aspect of writing. This caused issues when trying to format the data excluding the mistakes.\\\n",
    "Importing re I removed the special characters and punctuation. Making the data all lowercase as well as using the apostrophe dictionary so that the frequency distribution is accurate to an extent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c309297-f6a7-4b7f-a15e-5dde113f3733",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "The features are made using the sklearn package. With TF-IDF vectorization I generated features using a frequency distribution of all of the training data. This creates 1206 features. The TF-IDF vectorization is the measure of originality of a word. This is comparing the number of times the words are used in a document with the number of documents the words appear in.\\\n",
    "$TF-IDF = TF(t, d)* IDF(t)$\\\n",
    " where, $TF(t, d)$ = Number of times term \"t\" appears in a document \"d\". $IDF(t)$ = Inverse document frequency of the term t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701e74d-ec62-4ef6-8781-fe01d6961d3d",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "The model I used was the Suport Vector Machine model. Specifically I used the regression model. This made sections for the features provided based on the vector spaces they are located in. Playing around with the SVC as well as the linear and polynomial variations to get the best result I used the SVR Multi Output Regressor. This strategy fitts one regressor per target because natively they do not support multi-target regression. teh multiple targets in this instance being the classifications of each sections ie: 'syntax', and 'grammar' with values 1.0-5.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76733eb8-7d58-44bd-aa78-a28f769365d2",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "The score originally was 86% accuracy, but while trying to do cross validation with the cross_val_score method and got around 22% accuracy. I must be using it wrong or have done something fundamentally wrong. Using 5 segments for the cross validation all were very close. The standard deviation was negligable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc40af-41a6-422a-9e1a-92950cc2a7ec",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "With simple concepts quickly and accurately you can generate features and predictions that can be extremely useful. Looking at the top submissions for the kaggle competition, you can see just how impressively accurate they can be. Looking at a winning solutions write up we can see the approach used to win. The first place solution used different modeling approaches in combination.\n",
    "<ol>\n",
    "  <li>microsoft-deberta-v3-base</li>\n",
    "  <li>deberta-v3-large</li>\n",
    "  <li>deberta-v2-xlarge</li>\n",
    "  <li>roberta-large</li>\n",
    "    <li>distilbert-base-uncased</li>\n",
    "</ol>\n",
    "\n",
    "They also used different pooling techniques such as.\n",
    "\n",
    "<ol>\n",
    "  <li>mean pooling</li>\n",
    "  <li>concat pooling</li>\n",
    "  <li>weighted layer pooling</li>\n",
    "  <li>gem pooling</li>\n",
    "    <li>LSTM pooling</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
